{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRAVANTHI SHOROFF\\Anaconda3\\lib\\site-packages\\distributed\\utils.py:133: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "  RuntimeWarning,\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re, pickle\n",
    "le = LabelEncoder()\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Server name</th>\n",
       "      <th>Summary of the alert</th>\n",
       "      <th>Description</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Category</th>\n",
       "      <th>TimeRaised</th>\n",
       "      <th>TimeAdded</th>\n",
       "      <th>Type of the Alert (True or False)</th>\n",
       "      <th>Action to be taken</th>\n",
       "      <th>Ignorable or Non-Ignorable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Veeam VMware: Scheduled Task Failed</td>\n",
       "      <td>[ScheduledTaskFailedEvent] Task VMware vSphere...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>EventCollection</td>\n",
       "      <td>2018-10-10 19:44:48</td>\n",
       "      <td>2018-10-10 19:44:48</td>\n",
       "      <td>True</td>\n",
       "      <td>Can be ignored</td>\n",
       "      <td>Ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>UKMLWSQL904</td>\n",
       "      <td>Workflow Initialization: Failed to start a wor...</td>\n",
       "      <td>Data was found in the output, but has been dro...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>EventCollection</td>\n",
       "      <td>2019-04-09 22:56:48</td>\n",
       "      <td>2019-04-09 22:56:48</td>\n",
       "      <td>True</td>\n",
       "      <td>Can be ignored</td>\n",
       "      <td>Ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>UKMLWSQL904</td>\n",
       "      <td>MSSQL 2016: Discovery failed</td>\n",
       "      <td>Event ID: 7105. Management Group: TelefonicaUK...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Error</td>\n",
       "      <td>Alert</td>\n",
       "      <td>2019-04-09 22:56:48</td>\n",
       "      <td>2019-04-09 22:56:48</td>\n",
       "      <td>True</td>\n",
       "      <td>mail to DB team</td>\n",
       "      <td>Non-ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UKMLWSQL903</td>\n",
       "      <td>Workflow Initialization: Failed to start a wor...</td>\n",
       "      <td>Data was found in the output, but has been dro...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>EventCollection</td>\n",
       "      <td>2019-04-09 22:56:57</td>\n",
       "      <td>2019-04-09 22:56:57</td>\n",
       "      <td>True</td>\n",
       "      <td>Can be ignored</td>\n",
       "      <td>Ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>UKMLWSQL903</td>\n",
       "      <td>MSSQL 2016: Monitoring warning</td>\n",
       "      <td>Event ID: 4211. Management Group: TelefonicaUK...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Alert</td>\n",
       "      <td>2019-04-09 23:05:14</td>\n",
       "      <td>2019-04-09 23:05:14</td>\n",
       "      <td>True</td>\n",
       "      <td>mail to DB team</td>\n",
       "      <td>Non-ignorable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Server name                               Summary of the alert  \\\n",
       "0          NaN                Veeam VMware: Scheduled Task Failed   \n",
       "1  UKMLWSQL904  Workflow Initialization: Failed to start a wor...   \n",
       "2  UKMLWSQL904                       MSSQL 2016: Discovery failed   \n",
       "3  UKMLWSQL903  Workflow Initialization: Failed to start a wor...   \n",
       "4  UKMLWSQL903                     MSSQL 2016: Monitoring warning   \n",
       "\n",
       "                                         Description Priority Severity  \\\n",
       "0  [ScheduledTaskFailedEvent] Task VMware vSphere...   Normal  Warning   \n",
       "1  Data was found in the output, but has been dro...   Normal  Warning   \n",
       "2  Event ID: 7105. Management Group: TelefonicaUK...   Normal    Error   \n",
       "3  Data was found in the output, but has been dro...   Normal  Warning   \n",
       "4  Event ID: 4211. Management Group: TelefonicaUK...   Normal  Warning   \n",
       "\n",
       "          Category          TimeRaised           TimeAdded  \\\n",
       "0  EventCollection 2018-10-10 19:44:48 2018-10-10 19:44:48   \n",
       "1  EventCollection 2019-04-09 22:56:48 2019-04-09 22:56:48   \n",
       "2            Alert 2019-04-09 22:56:48 2019-04-09 22:56:48   \n",
       "3  EventCollection 2019-04-09 22:56:57 2019-04-09 22:56:57   \n",
       "4            Alert 2019-04-09 23:05:14 2019-04-09 23:05:14   \n",
       "\n",
       "  Type of the Alert (True or False) Action to be taken   \\\n",
       "0                              True      Can be ignored   \n",
       "1                              True      Can be ignored   \n",
       "2                              True     mail to DB team   \n",
       "3                              True      Can be ignored   \n",
       "4                              True     mail to DB team   \n",
       "\n",
       "  Ignorable or Non-Ignorable  \n",
       "0                  Ignorable  \n",
       "1                  Ignorable  \n",
       "2              Non-ignorable  \n",
       "3                  Ignorable  \n",
       "4              Non-ignorable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'SCOM2016_Alerts_Updated1.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5318, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Server name', 'Summary of the alert', 'Description', 'Priority',\n",
       "       'Severity', 'Category', 'TimeRaised', 'TimeAdded',\n",
       "       'Type of the Alert (True or False)', 'Action to be taken ',\n",
       "       'Ignorable or Non-Ignorable'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Summary of the alert','Ignorable or Non-Ignorable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5318, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Summary of the alert', 'Ignorable or Non-Ignorable'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-ignorable    4199\n",
       "Ignorable        1119\n",
       "Name: Ignorable or Non-Ignorable, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Ignorable or Non-Ignorable']=df1['Ignorable or Non-Ignorable'].apply(lambda x: 1 if (x)==\"Non-ignorable\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4199\n",
       "0    1119\n",
       "Name: Ignorable or Non-Ignorable, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Health Service Heartbeat Failure                                                  2124\n",
       "Clean Shutdown Initiated                                                           559\n",
       "Failed to Connect to Computer                                                      342\n",
       "Dell OMSS Controller event log (3)                                                 189\n",
       "Cluster resource group offline or partially online                                 130\n",
       "                                                                                  ... \n",
       "Dell OMSS Controller write policy has been changed to Write Back                     1\n",
       "Management point relaymgr backlog alert                                              1\n",
       "Operations Manager Web Console Unavailable                                           1\n",
       "SSRS 2012: An Error occurred during execution of a SSRS 2012 MP managed module       1\n",
       "Alert Parameter Replacement Failure                                                  1\n",
       "Name: Summary of the alert, Length: 190, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     Veeam VMware: Scheduled Task Failed\n",
       "1       Workflow Initialization: Failed to start a wor...\n",
       "2                            MSSQL 2016: Discovery failed\n",
       "3       Workflow Initialization: Failed to start a wor...\n",
       "4                          MSSQL 2016: Monitoring warning\n",
       "                              ...                        \n",
       "5313                             Clean Shutdown Initiated\n",
       "5314                             Clean Shutdown Initiated\n",
       "5315    MSSQL on Windows: Buffer Cache Hit Ratio is to...\n",
       "5316             Dell OMSS Controller battery is charging\n",
       "5317       Dell OMSS The battery charge cycle is complete\n",
       "Name: Summary of the alert, Length: 5318, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "5313    1\n",
       "5314    1\n",
       "5315    1\n",
       "5316    0\n",
       "5317    0\n",
       "Name: Ignorable or Non-Ignorable, Length: 5318, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Summary of the alert'] = df1['Summary of the alert'].apply(lambda x: x.lower())\n",
    "# df['Alert'] = df['Alert'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Summary of the alert'] = df1['Summary of the alert'].apply(lambda s: re.sub(r\"[^a-zA-Z0-9]\",\" \",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens =[w for w in tokens if not w in stop_words] # [w for w in\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      veeam vmware scheduled task failed\n",
       "1       workflow initialization failed start workflow ...\n",
       "2                             mssql 2016 discovery failed\n",
       "3       workflow initialization failed start workflow ...\n",
       "4                           mssql 2016 monitoring warning\n",
       "                              ...                        \n",
       "5313                             clean shutdown initiated\n",
       "5314                             clean shutdown initiated\n",
       "5315              mssql window buffer cache hit ratio low\n",
       "5316                dell omss controller battery charging\n",
       "5317              dell omss battery charge cycle complete\n",
       "Name: Summary of the alert, Length: 5318, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector=TfidfVectorizer(use_idf=True,max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfidf_vector.fit_transform(df1['Summary of the alert']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tf, open(\"vectorized.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"vectorized.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking X and y\n",
    "X = vectorizer\n",
    "y = df1['Ignorable or Non-Ignorable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Logistic Regression classification report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       287\n",
      "           1       0.99      1.00      0.99      1043\n",
      "\n",
      "    accuracy                           0.99      1330\n",
      "   macro avg       0.99      0.97      0.98      1330\n",
      "weighted avg       0.99      0.99      0.99      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glmMod = LogisticRegression()\n",
    "glmMod.fit(X_train, y_train)\n",
    "y_pred=glmMod.predict(X_test)\n",
    "print(\"\\n\\n***** Logistic Regression classification report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logisticregressionMod.pkl'\n",
    "pickle.dump(glmMod, open('logisticregressionMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** RandomForestClassifier report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       283\n",
      "           1       1.00      1.00      1.00      1047\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      0.99      0.99      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfMod = RandomForestClassifier()\n",
    "rfMod.fit(X_train, y_train)\n",
    "y_pred=rfMod.predict(X_test)\n",
    "print(\"\\n\\n***** RandomForestClassifier report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'randomforestMod.pkl'\n",
    "pickle.dump(rfMod, open('randomforestMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** GradientBoosting report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       283\n",
      "           1       0.99      1.00      0.99      1047\n",
      "\n",
      "    accuracy                           0.99      1330\n",
      "   macro avg       0.99      0.98      0.99      1330\n",
      "weighted avg       0.99      0.99      0.99      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbMod = GradientBoostingClassifier()\n",
    "gbMod.fit(X_train, y_train)\n",
    "y_pred=gbMod.predict(X_test)\n",
    "print(\"\\n\\n***** GradientBoosting report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gradientboostMod.pkl'\n",
    "pickle.dump(gbMod, open('gradientboostMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Adaboost report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       283\n",
      "           1       1.00      1.00      1.00      1047\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaMod = AdaBoostClassifier()\n",
    "adaMod.fit(X_train, y_train)\n",
    "y_pred = adaMod.predict(X_test)\n",
    "print(\"\\n\\n***** Adaboost report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adaboostMod.pkl'\n",
    "pickle.dump(adaMod, open('adaboostMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Model Ensemble score report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       283\n",
      "           1       1.00      1.00      1.00      1047\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      0.99      0.99      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingMod = VotingClassifier(estimators=[('LogisticRegression', glmMod),('RandomForrest', rfMod),(\"GradientBoosting\",gbMod),(\"AdaBoost\",adaMod)], voting='soft')\n",
    "votingMod = votingMod.fit(X_train, y_train)\n",
    "test_labels=votingMod.predict((X_test))\n",
    "#votingMod.score(X_test_transform, y_test)\n",
    "\n",
    "print(\"\\n\\n***** Model Ensemble score report:*****\\n\")\n",
    "print(classification_report(y_test, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'votingclassifierMod.pkl'\n",
    "pickle.dump(votingMod, open('votingclassifierMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_ML'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = 'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_ML\\\\votingclassifierMod.pkl'\n",
    "with open(pkl_file,'rb') as file:\n",
    "        votingclassifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict class\n",
    "y_pred = votingclassifier.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1119\n",
      "           1       1.00      1.00      1.00      4199\n",
      "\n",
      "    accuracy                           1.00      5318\n",
      "   macro avg       1.00      0.99      1.00      5318\n",
      "weighted avg       1.00      1.00      1.00      5318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns=['y_pred'],data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4213\n",
       "0    1105\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['y_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['pred_val'] = output['y_pred'].replace(to_replace=1,value='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    4213\n",
       "0      1105\n",
       "Name: pred_val, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['pred_val'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_output = output[output['pred_val']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
